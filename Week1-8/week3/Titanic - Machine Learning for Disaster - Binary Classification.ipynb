{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Week 3] AI Saturdays - AI Developers, Boise\n",
    "- June 2, 2018\n",
    "- Prepared by: Ashish Sharma <accssharma@gmail.com>\n",
    "\n",
    "## Titanic: Machine Learning from Disaster (Kaggle)\n",
    "\n",
    "### Competition Detail\n",
    "\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n",
    "\n",
    "### Viewing Titanic as a Machine Learning problem\n",
    "\n",
    "**Definition 1:**\n",
    "\n",
    "`Machine learning is the science of getting computers to act without being explicitly programmed.`\n",
    "\n",
    "\n",
    "**Definition 2:** \n",
    "\n",
    "`A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.`\n",
    "\n",
    "#### Task (T)\n",
    "- Binary Classification Problem (passengers survived or not)\n",
    "\n",
    "#### Experience (E)\n",
    "- passengers: “features” like passengers’ gender and class. [input (X)]\n",
    "- did passenger survive the disaster: yes or no [output (y)]\n",
    "\n",
    "#### Performance (P)\n",
    "\n",
    "#### Mathematical Interpretation\n",
    "- Just a simple function approximation i.e. find a relationship between X and y.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "#### The training set (train.csv)\n",
    "- used to build/train your machine learning models.\n",
    "- Along with the input data, we also have the outcome (also known as the “ground truth”) for each passenger. \n",
    "- Input (X): “features” like passengers’ gender and class. \n",
    "- Output (y): whether passenger survived\n",
    "\n",
    "#### The test set \n",
    "- used to see how well your model performs on unseen data.\n",
    "- For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n",
    "\n",
    "<img src=\"imgs/kaggle_titanic_data.png\" height=550 width=900/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Know about different types of data\n",
    "- [General data types](https://towardsdatascience.com/data-types-in-statistics-347e152e8bee)\n",
    "- [Tutorial reference](https://www.kaggle.com/startupsci/titanic-data-science-solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis, manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(9,6)})\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_csv = \"/home/asharma/.kaggle/competitions/titanic/train.csv\"\n",
    "test_csv = \"/home/asharma/.kaggle/competitions/titanic/test.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_csv)\n",
    "# quickly peek through a few of the training data\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(test_csv)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "- Let's quickly check the types and very basic statistic about our variables (each column) in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train.info()\n",
    "print(\"-\"*40)\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the distribution of numerical feature values across the samples?**\n",
    "\n",
    "This helps us determine, among other early insights, how representative is the training dataset of the actual problem domain.\n",
    "\n",
    "- Total samples are 891 or 40% of the actual number of passengers on board the Titanic (2,224).\n",
    "- Survived is a categorical feature with 0 or 1 values.\n",
    "- Around 38% samples survived representative of the actual survival rate at 32%.\n",
    "- Most passengers (> 75%) did not travel with parents or children.\n",
    "- Nearly 30% of the passengers had siblings and/or spouse aboard.\n",
    "- Fares varied significantly with few passengers (<1%) paying as high as $512.\n",
    "- Few elderly passengers (<1%) within age range 65-80.\n",
    "\n",
    "**What is the distribution of categorical features?**\n",
    "\n",
    "- Names are unique across the dataset (count=unique=891)\n",
    "- Sex variable as two possible values with 65% male (top=male, freq=577/count=891).\n",
    "- Cabin values have several dupicates across samples. Alternatively several passengers shared a cabin.\n",
    "- Embarked takes three possible values. S port used by most passengers (top=S)\n",
    "- Ticket feature has high ratio (22%) of duplicate values (unique=681)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# descriptive statistics of training data\n",
    "df_train.describe(include=['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics of training data\n",
    "df_test.describe(include=['number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which features are categorical?**\n",
    "\n",
    "These values classify the samples into sets of similar samples. Within categorical features are the values nominal, ordinal, ratio, or interval based? Among other things this helps us select the appropriate plots for visualization.\n",
    "\n",
    "- Categorical: Survived, Sex, and Embarked. Ordinal: Pclass.\n",
    "\n",
    "**Which features are numerical?**\n",
    "\n",
    "Which features are numerical? These values change from sample to sample. Within numerical features are the values discrete, continuous, or timeseries based? Among other things this helps us select the appropriate plots for visualization.\n",
    "\n",
    "- Continous: Age, Fare. Discrete: SibSp, Parch.\n",
    "\n",
    "**Which features are mixed data types?**\n",
    "\n",
    "Numerical, alphanumeric data within same feature. These are candidates for correcting goal.\n",
    "\n",
    "- Ticket is a mix of numeric and alphanumeric data types. Cabin is alphanumeric.\n",
    "\n",
    "**Which features may contain errors or typos?**\n",
    "\n",
    "This is harder to review for a large dataset, however reviewing a few samples from a smaller dataset may just tell us outright, which features may require correcting.\n",
    "\n",
    "- Name feature may contain errors or typos as there are several ways used to describe a name including titles, round brackets, and quotes used for alternative or short names.\n",
    "\n",
    "**Which features contain blank, null or empty values?**\n",
    "\n",
    "These will require correcting.\n",
    "\n",
    "- Cabin > Age > Embarked features contain a number of null values in that order for the training dataset.\n",
    "- Cabin > Age are incomplete in case of test dataset.\n",
    "\n",
    "**What are the data types for various features?**\n",
    "\n",
    "Helping us during converting goal.\n",
    "\n",
    "- Seven features are integer or floats. Six in case of test dataset.\n",
    "- Five features are strings (object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(df_train)\n",
    "df_train[\"Survived\"].value_counts()\n",
    "print (\"Dataset: \", 891/2224, \"% representation of the population\" )\n",
    "# total surived ration in our data\n",
    "print (\"Sample survival rate:\", 342/891)\n",
    "# 492 passengers and 214 crew were saved in real among 2224 total passengers\n",
    "print(\"True survival rate:\", 706/2224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passengers with no parents or siblings\n",
    "df_train[(df_train[\"Parch\"] == 0) | (df_train[\"SibSp\"] == 0)].shape[0]/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many people survived who had either parents or siblings?\n",
    "df_train[(df_train[\"Parch\"] == 0) | (df_train[\"SibSp\"] == 0) & (df_train[\"Survived\"] == 1)].shape[0]/num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count plot - frequency plot of different possible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Survived\", data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"SibSp\", data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Parch\", data=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram - frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df_train, col='Survived')\n",
    "g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box plot - Numerical continuous variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_boxplot(_data):\n",
    "    d = sns.boxplot(x=_data)\n",
    "\n",
    "sns.boxplot(data=df_train[[\"Age\", \"Fare\"]], orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_boxplot(df_train[\"Fare\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plots - relationship between different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Survived\", y=\"Age\", hue=\"Pclass\", data=df_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Survived\", y=\"Sex\", data=df_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facetgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(df_train, col='Survived', row='Pclass', size=2.2, aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(df_train, col='Survived', row='Pclass', size=2.2, aspect=1.6)\n",
    "grid.map(plt.hist, 'Fare', alpha=.5, bins=20)\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(df_train, row='Embarked', col='Survived', size=2.2, aspect=1.6)\n",
    "grid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot - relationship between two continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df_train[\"Age\"], y=df_train[\"Fare\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations and Decisions\n",
    "\n",
    "- Consider Age in our model training - handle missing data\n",
    "    - Most passengers are in 15-35 age range.\n",
    "    - Oldest passengers (Age = 80) survived.\n",
    "    - Large number of 15-25 year olds did not survive.\n",
    "    - should band age groups?\n",
    "- Consider Pclass for model training\n",
    "     - Pclass=3 had most passengers, however most did not survive. \n",
    "     - Infant passengers in Pclass=2 and Pclass=3 mostly survived\n",
    "     - Most passengers in Pclass=1 survived\n",
    "     - Pclass varies in terms of Age distribution of passengers\n",
    "- Consider Fare\n",
    "    - Higher fare paying passengers had better survival. \n",
    "- Consider Sex\n",
    "    - Female passengers had much better survival rate than males\n",
    "- Consider Parch and SibSp\n",
    "    - more than 80% of people who survived did not travel with Parch, Sibling or Spouse\n",
    "- We drop Cabin column\n",
    "    - More than 75% of data is missing\n",
    "- Consider Embarked - handle missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing data\n",
    "- we need to handle for Age and Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the column-wise missing values count\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Embarked feature takes S, Q, C values based on port of embarkation. Our training dataset has two missing values. We simply fill these with the most common occurance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_port = df_train.Embarked.dropna().mode()[0]\n",
    "freq_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.Embarked= df_train.Embarked.fillna(freq_port)\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Age is a continuous numerical feature, even though does not make much sense, for simplicity, we impute the missing values with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ag_mean_tr = df_train.Age.dropna().mean()\n",
    "df_train.Age = df_train.Age.fillna(ag_mean_tr)\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Similarly, impute missing Age values in test data with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ag_mean_tst = df_test.Age.dropna().mean()\n",
    "df_test.Age = df_test.Age.fillna(ag_mean_tst)\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Similary, impute Fare with mean value in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ag_mean_tst = df_test.Fare.dropna().mean()\n",
    "df_test.Fare = df_test.Fare.fillna(ag_mean_tst)\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()\n",
    "print(\"-\"*40)\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert categorical features to  numerical features\n",
    "- one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "\n",
    "def handle_categorical_data(df):\n",
    "    for col, t in df.dtypes.iteritems():\n",
    "        if col in categorical_features: \n",
    "            df[col] = df[col].astype(\"category\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categorical_X = handle_categorical_data(df_train).select_dtypes(include=\"category\")\n",
    "categorical_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarly for test data\n",
    "categorical_X_test = handle_categorical_data(df_test).select_dtypes(include=\"category\")\n",
    "categorical_X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categorical_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_cat_to_num = pd.get_dummies(categorical_X)\n",
    "final_cat_to_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cat_to_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_cat_to_num_test = pd.get_dummies(categorical_X_test)\n",
    "final_cat_to_num_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cat_to_num_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[\"Survived\"].copy()\n",
    "# X_test  = test_df.drop(\"PassengerId\", axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop([\"Survived\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_numerical_data(df):\n",
    "    numerical_X = df.select_dtypes(\"number\")\n",
    "    if \"PassengerId\" in numerical_X.columns:\n",
    "        numerical_X = numerical_X.drop([\"PassengerId\"], axis=1)\n",
    "    return numerical_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical_X = get_numerical_data(df_train)\n",
    "numerical_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numerical_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# do same thing for test data\n",
    "numerical_X_test = get_numerical_data(df_test)\n",
    "numerical_X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train  = pd.concat([numerical_X, final_cat_to_num], axis=1)\n",
    "y_train = y\n",
    "\n",
    "# verify that we have same number of examples in X_train and y\n",
    "assert X_train.shape[0] == len(y)\n",
    "\n",
    "X_test = pd.concat([numerical_X_test, final_cat_to_num_test], axis=1)\n",
    "\n",
    "print(\"X train shape: \", X_train.shape)\n",
    "print(\"y train shape: \", y_train.shape)\n",
    "print(\"X test shape: \", X_test.shape)\n",
    "\n",
    "# verify that we have same number of features in X_train and X_test\n",
    "assert X_train.shape[1] == X_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a machine learning model\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "- Logistic regression is a statistical method for analyzing a dataset in which there are one or more independent variables that determine an outcome. In the simplest form, the outcome is measured with a dichotomous variable (in which there are only two possible outcomes).\n",
    "\n",
    "- probabilistic, parametric model\n",
    "    - The logistic regression model is parametric because it has a finite set of parameters. Specifically, the parameters are the regression coefficients. These usually correspond to one for each predictor plus a constant. Logistic regression is a particular form of the generalised linear model.\n",
    "    - Logistic regression is probabilistic because it assumes that P(Y=1) is the probability of the event occurring\n",
    "\n",
    "- Logistic regression can handle all sorts of relationships, because it applies a non-linear log transformation to the predicted odds ratio.\n",
    "- The independent variables do not need to be multivariate normal – although multivariate normality yields a more stable solution.\n",
    "\n",
    "#### Assumptions\n",
    "- It does not need a linear relationship between the dependent and independent variables. (Linear Regression, particularly that are solved using OLS method, does)\n",
    "- Logistic regression assumes that P(Y=1) is the probability of the event occurring\n",
    "- The model should be fitted correctly (concepts of overfitting, underfitting)\n",
    "- Logistic regression requires each observation to be independent\n",
    "- The larger the dataset, the better is the modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A very simple implementation of Logistic Regression as Black-box\n",
    "\n",
    "# create an instance of logistic regression\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# make a prediction\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "Y_pred_prob = clf.predict_proba(X_test)\n",
    "#Y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another Example: Logistic Regression fitting vs Linear REgression fitting (Visualization in 2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Code source: Gael Varoquaux\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "# this is our test set, it's just a straight line with some\n",
    "# Gaussian noise\n",
    "xmin, xmax = -5, 5\n",
    "n_samples = 100\n",
    "np.random.seed(0)\n",
    "X = np.random.normal(size=n_samples)\n",
    "y = (X > 0).astype(np.float)\n",
    "X[X > 0] *= 4\n",
    "X += .3 * np.random.normal(size=n_samples)\n",
    "\n",
    "X = X[:, np.newaxis]\n",
    "# run the classifier\n",
    "clf = linear_model.LogisticRegression(C=1e5)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# and plot the result\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.clf()\n",
    "plt.scatter(X.ravel(), y, color='black', zorder=20)\n",
    "X_test = np.linspace(-5, 10, 300)\n",
    "\n",
    "\n",
    "def model(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "loss = model(X_test * clf.coef_ + clf.intercept_).ravel()\n",
    "plt.plot(X_test, loss, color='red', linewidth=3)\n",
    "\n",
    "ols = linear_model.LinearRegression()\n",
    "ols.fit(X, y)\n",
    "plt.plot(X_test, ols.coef_ * X_test + ols.intercept_, linewidth=1)\n",
    "plt.axhline(.5, color='.5')\n",
    "\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('X')\n",
    "plt.xticks(range(-5, 10))\n",
    "plt.yticks([0, 0.5, 1])\n",
    "plt.ylim(-.25, 1.25)\n",
    "plt.xlim(-4, 10)\n",
    "plt.legend(('Logistic Regression Model', 'Linear Regression Model'),\n",
    "           loc=\"lower right\", fontsize='small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
